{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0401c217-d93d-4ab5-95ea-fbf45f768f24",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22f88f52-69f5-4691-b967-277a56f51e07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA applied XGBoost R2 Score 0.1890\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"cnn_features_combined.csv\")\n",
    "df = df.drop(columns=[\"Id\"], errors=\"ignore\")\n",
    "\n",
    "# Select only CNN feature vectors excluding metadata\n",
    "cnn_features = df.filter(like=\"feature_\", axis=1)\n",
    "\n",
    "# Apply PCA to reduce dimensionality to 100 components\n",
    "pca = PCA(n_components=100)\n",
    "X_pca = pca.fit_transform(cnn_features)\n",
    "\n",
    "# Combine PCA-transformed features with existing metadata\n",
    "df_pca = pd.concat([df.drop(columns=cnn_features.columns), pd.DataFrame(X_pca)], axis=1)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train_pca, X_test_pca, y_train, y_test = train_test_split(df_pca.drop(columns=[\"Pawpularity\"]), df_pca[\"Pawpularity\"], test_size=0.2, random_state=42)\n",
    "\n",
    "# Define XGBoost model\n",
    "xgb_model = XGBRegressor(\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=5,\n",
    "    tree_method=\"hist\",  # Optimize memory usage\n",
    "    enable_categorical=False,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train the XGBoost model using PCA-transformed features\n",
    "xgb_model.fit(X_train_pca, y_train)\n",
    "y_pred_pca = xgb_model.predict(X_test_pca)\n",
    "\n",
    "# Evaluate model performance\n",
    "r2_pca = r2_score(y_test, y_pred_pca)\n",
    "print(f\"PCA applied XGBoost R2 Score {r2_pca:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56ef5c1f-7bac-48a0-af2c-a1e5096e4aa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost - Mean Squared Error (MSE): 357.7013\n",
      "XGBoost - R² Score: 0.1908\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "df = pd.read_csv(\"cnn_features_combined.csv\")\n",
    "df = df.drop(columns=[\"Id\"], errors=\"ignore\")\n",
    "\n",
    "target_column = \"Pawpularity\"  # Target Variable\n",
    "X = df.drop(columns=[target_column])  # Independent Variable (CNN Vectors + Metadata)\n",
    "y = df[target_column]  # Target Variable (Pawpularity Score)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "xgb_model = XGBRegressor(\n",
    "    n_estimators=100,  \n",
    "    learning_rate=0.1,  \n",
    "    max_depth=5,  \n",
    "    random_state=42\n",
    ")\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "\n",
    "mse_xgb = mean_squared_error(y_test, y_pred_xgb)\n",
    "r2_xgb = r2_score(y_test, y_pred_xgb)\n",
    "\n",
    "print(f\"XGBoost - Mean Squared Error (MSE): {mse_xgb:.4f}\")\n",
    "print(f\"XGBoost - R² Score: {r2_xgb:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ace35fdd-ec99-42d4-a417-5af52119f10c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Selection applied XGBoost - MSE: 366.3011\n",
      "Feature Selection applied XGBoost R2 Score 0.1713\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Select top 100 features based on correlation with the target variable\n",
    "selector = SelectKBest(f_regression, k=100)\n",
    "X_selected = selector.fit_transform(X_train, y_train)\n",
    "\n",
    "# Train XGBoost using the selected features\n",
    "xgb_model.fit(X_selected, y_train)\n",
    "y_pred_selected = xgb_model.predict(selector.transform(X_test))\n",
    "\n",
    "# Evaluate model performance\n",
    "mse_selected = mean_squared_error(y_test, y_pred_selected)\n",
    "r2_selected = r2_score(y_test, y_pred_selected)\n",
    "\n",
    "print(f\"Feature Selection applied XGBoost - MSE: {mse_selected:.4f}\")\n",
    "print(f\"Feature Selection applied XGBoost R2 Score {r2_selected:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa58ba5-95e4-4716-83d8-0dbbc5244b0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
